<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description"
          content="Deep Surface Light Fields">
    <meta name="author" content="Anpei Chen,
                                Minye Wu,
                                Yingliang Zhang,
                                Nianyi Li,
								Jie Lu,
                                Shenghua Gao,
                                Jingyi Yu">

    <title>Deep Surface Light Fields</title>
    <!-- Bootstrap core CSS -->
    <!--link href="bootstrap.min.css" rel="stylesheet"-->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css"
          integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">

    <!-- Custom styles for this template -->
    <link href="offcanvas.css" rel="stylesheet">
    <!--    <link rel="icon" href="img/favicon.gif" type="image/gif">-->
</head>

<body>
<div class="jumbotron jumbotron-fluid">
    <div class="container"></div>
    <h2>Deep Surface Light Fields</h2>
     <h3>I3D 2018</h3>
           <p class="abstract">A MLP based free-viewpoint renderer.</p>
    <hr>
    <p class="authors">
        <a href="https://apchenstu.github.io/"> Anpei Chen</a>,
        <a href="https://wuminye.com/"> Mingye Wu</a>,
        <a href="https://scholar.google.com/citations?user=dnjU2RMAAAAJ&hl=en"> Yingliang Zhang</a>,
        <a href="https://sites.duke.edu/nianyi/"> Nianyi Li</a>,
        <a > Jie Lu</a> </br>
        <a href="https://svip-lab.github.io/news.html"> Shenghua Gao</a>,
        <a href="http://www.yu-jingyi.com/cv/"> Jingyi Yu</a>
    </p>
    <div class="btn-group" role="group" aria-label="Top menu">
        <a class="btn btn-primary" href="https://arxiv.org/abs/1810.06514">Paper</a>
        <a class="btn btn-primary" href="https://drive.google.com/open?id=1up8ZfUtrlf7DnTUrzFAA3_qqZHNA6d6C">Slides</a>
    </div>
</div>

<div class="container">
    <div class="section">
        <div class="vcontainer">
            <iframe class='video' src="https://www.youtube.com/embed/OhJTjkukARc" frameborder="0"
                    allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture"
                    allowfullscreen></iframe>
        </div>
        <hr>
        <p>
            A surface light field represents the radiance of rays originating from
            any points on the surface in any directions. Traditional approaches
            require ultra-dense sampling to ensure the rendering quality. In this
            paper, we present a novel neural network based technique called
            deep surface light field or DSLF to use only moderate sampling for
            high fidelity rendering. DSLF automatically fills in the missing data
            by leveraging different sampling patterns across the vertices and at
            the same time eliminates redundancies due to the networkâ€™s prediction capability. For real data, we address the image registration
            problem as well as conduct texture-aware remeshing for aligning
            texture edges with vertices to avoid blurring. Comprehensive experiments show that DSLF can further achieve high data compression
            ratio while facilitating real-time rendering on the GPU.
        </p>
    </div>


    <div class="section">
        <h2>Neural Renderer</h2>
        <hr>
        <p>
            (a) Our deep surface light field (<b>DSLF</b>) network structure. The fully connected (FC) layers L1 and L2 subnets take ray
            coordinates as inputs and output to the FC T subnet, with an additional skip layer (yellow arrow). (b) shows a sample input(top)
            and per-vertex prediction(bottom). (c) shows the final output after rasterisation.
        </p>
        <div class="row align-items-center">
            <div class="col justify-content-center text-center">
                <img src="img/network.png" style="width:100%; margin-right:-10px; margin-top:-10px;">
        </div> 
    </div>

    <div class="section">
        <h2>Result</h2>
        <hr>
        <div class="row align-items-center">
            <div class="col justify-content-center text-center">
                <img src="img/result.png" style="width:100%; margin-right:-10px; margin-top:-10px;">
        </div>
        <p>
            We train our MVSNeRF with scenes of objects in the DTU dataset. Our network can effectively <b>generalize</b> across diverse scenes; even for a complex indoor scene, our network can reconstruct a neural radiance field from only three input images (a) and synthesize a realistic image from a novel viewpoint (b). While this result contains artifacts, it can be largely improved by fine-tuning our reconstruction on more images for only <b>6 min</b> (c), which achieves better quality than the NeRF's nerf result (d) from 9.5h per-scene optimization. 
        </p>
    </div>

    <div class="section">
        <h2>Paper</h2>
        <hr>
        <div>
            <div class="list-group">
                <a href="https://arxiv.org/abs/1810.06514"
                   class="list-group-item">
                    <img src="img/paper_thumbnail.png" style="width:100%; margin-right:-20px; margin-top:-10px;">
                </a>
            </div>
        </div>
    </div>

    <div class="section">
        <h2>Bibtex</h2>
        <hr>
        <div class="bibtexsection">
            @article{chen2018deep,
              title={Deep surface light fields},
              author={Chen, Anpei and Wu, Minye and Zhang, Yingliang and Li, Nianyi and Lu, Jie and 
              Gao, Shenghua and Yu, Jingyi},
              journal={Proceedings of the ACM on Computer Graphics and Interactive Techniques},
              volume={1},
              number={1},
              pages={1--17},
              year={2018},
              publisher={ACM New York, NY, USA}
            }
        </div>
    </div>

    <hr>

    <footer>
        <p>Send feedback and questions to <a href="https://apchenstu.github.io/">Anpei Chen</a></p>
    </footer>
</div>


<script src="https://code.jquery.com/jquery-3.5.1.slim.min.js"
        integrity="sha384-DfXdz2htPH0lsSSs5nCTpuj/zy4C+OGpamoFVy38MVBnE+IbbVYUew+OrCXaRkfj"
        crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js"
        integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo"
        crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.0/js/bootstrap.min.js"
        integrity="sha384-OgVRvuATP1z7JjHLkuOU7Xw704+h835Lr+6QL9UvYjZE3Ipu6Tp75j7Bh/kR0JKI"
        crossorigin="anonymous"></script>

</body>
</html>
